{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8TxjN86hbBM",
    "outputId": "f7b4f133-67f9-464c-830b-fd108a5929ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "np-4AkqCQL5Y"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sX-eI0j5vAIt",
    "outputId": "2a50cc9c-b83e-473b-b030-00182e9e93ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLqiUuN5hbBN"
   },
   "source": [
    "Next, we'll set the random seeds for reproducability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Y60KneFJhbBN"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "tmMfq9JlhbBO"
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower = True)\n",
    "PTB_TAGS = data.Field(unk_token = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Fm8eRTtYhbBP"
   },
   "outputs": [],
   "source": [
    "fields = ((\"text\", TEXT), (\"ptbtags\", PTB_TAGS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zft-lTJyqP66",
    "outputId": "277e0cae-5593-41a3-96e1-7afed32bba23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A Saudi woman issues a voice recording in which she mourns her brother and demands the punishment of his killers', 'DT JJ NN VBZ DT NN NN IN WDT PRP VBZ PRP$ NN CC VBZ DT NN IN PRP$ NNS'), ('HAD1999 In a unique way , a young Saudi woman has resorted to issuing a sound tape in which she mourns her brother murdered in Hafr Al Batin , in the hope of rekindling interest in his case , in which 3 young men were accused of killing him and which has not so far been resolved', 'NNP IN DT JJ NN , DT JJ JJ NN VBZ VBN IN VBG DT NN NN IN WDT PRP VBZ PRP$ NN VBN IN NNP NNP NNP , IN DT NN IN VBG NN IN PRP$ NN , IN WDT CD JJ NNS VBD VBN IN VBG PRP CC WDT VBZ RB RB RB VBN VBN'), (\"The tape contains excerpts of poetry , dramatic voice recitals , detailed accounts of the young man 's murder circumstances of the background to the investigation of the case for which the young woman is demanding expedited proceedings and punishment of those involved\", 'DT NN VBZ NNS IN NN , JJ NN NNS , JJ NNS IN DT JJ NN POS NN NNS IN DT NN IN DT NN IN DT NN IN WDT DT JJ NN VBZ VBG VBN NNS CC NN IN DT VBN')]\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "with open('/content/gdrive/My Drive/Colab Notebooks/ontonotes.tsv', 'r') as f:\n",
    "  data_f = f.readlines()\n",
    "  single_sentence = ''\n",
    "  label = ''\n",
    "  for i in data_f:\n",
    "    sentence = i.strip().split('\\t')\n",
    "    #print(sentence[0])\n",
    "    if sentence[0] == '*':\n",
    "      continue\n",
    "    if sentence[1] != '.':\n",
    "      single_sentence += sentence[1] + ' '\n",
    "      #print(single_sentence)\n",
    "      label += sentence[2] + ' '\n",
    "      #print(label)\n",
    "    if sentence[1] == '.':\n",
    "      data_list.append((single_sentence.strip(), label.strip()))\n",
    "      single_sentence = ''\n",
    "      label = ''\n",
    "print(data_list[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "NILCQQCQpyij"
   },
   "outputs": [],
   "source": [
    "examples = list(map(lambda x: data.example.Example.fromlist(list(x), fields=fields), data_list))\n",
    "\n",
    "train_data = data.Dataset(examples[:45000], fields=fields)\n",
    "valid_data = data.Dataset(examples[45000:50000], fields=fields)\n",
    "test_data = data.Dataset(examples[50000:], fields=fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9LKImsJhbBQ"
   },
   "source": [
    "We can check how many examples are in each section of the dataset by checking their length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qkPeUdHRhbBQ",
    "outputId": "1696d1fb-ae63-4f3a-b050-e074b27b8e82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 45000\n",
      "Number of validation examples: 5000\n",
      "Number of testing examples: 6519\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data)}\")\n",
    "print(f\"Number of testing examples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgG2gJbihbBS"
   },
   "source": [
    "Let's print out an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8KcrgS9lhbBS",
    "outputId": "02a26a2b-1e43-4e5a-9f36-5265349fd409"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['a', 'saudi', 'woman', 'issues', 'a', 'voice', 'recording', 'in', 'which', 'she', 'mourns', 'her', 'brother', 'and', 'demands', 'the', 'punishment', 'of', 'his', 'killers'], 'ptbtags': ['DT', 'JJ', 'NN', 'VBZ', 'DT', 'NN', 'NN', 'IN', 'WDT', 'PRP', 'VBZ', 'PRP$', 'NN', 'CC', 'VBZ', 'DT', 'NN', 'IN', 'PRP$', 'NNS']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eyBqlw4hbBT"
   },
   "source": [
    "We can also view the text and tags separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1iYyFXWchbBT",
    "outputId": "cb1e58a1-4964-43d9-b4d5-f5daa008bd35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'saudi', 'woman', 'issues', 'a', 'voice', 'recording', 'in', 'which', 'she', 'mourns', 'her', 'brother', 'and', 'demands', 'the', 'punishment', 'of', 'his', 'killers']\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0])['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PIWSaEnVhbBU",
    "outputId": "9e19f79b-8a47-4aab-b99d-d7c0b7a7bb49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DT', 'JJ', 'NN', 'VBZ', 'DT', 'NN', 'NN', 'IN', 'WDT', 'PRP', 'VBZ', 'PRP$', 'NN', 'CC', 'VBZ', 'DT', 'NN', 'IN', 'PRP$', 'NNS']\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0])['ptbtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "irkzQ5mLhbBW"
   },
   "outputs": [],
   "source": [
    "MIN_FREQ = 2\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 min_freq = MIN_FREQ)\n",
    "\n",
    "\n",
    "PTB_TAGS.build_vocab(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "qdDzmnvQc4ne"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-cased\")\n",
    "model.eval()\n",
    "\n",
    "def get_bert_emb(word):\n",
    "  encoded_input = tokenizer(word, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "  with torch.no_grad():\n",
    "      model_output = model(**encoded_input)\n",
    "\n",
    "      return model_output[0][0][1].numpy()\n",
    "\n",
    "vocab_df = pd.DataFrame({'vocab':list(TEXT.vocab.stoi.keys())})\n",
    "vocab_df['emb'] = vocab_df['vocab'].apply(get_bert_emb)\n",
    "vocab_df.to_pickle(\"vocab_emb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "rqBB-_kU2eBn",
    "outputId": "ef82ce6e-2c70-4492-ecd8-d34cb5f89d8c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>[0.10041629, 0.21012346, 0.16489458, -0.108804...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;pad&gt;</td>\n",
       "      <td>[-0.020771498, 0.32556504, 0.059507508, -0.014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>[0.5092548, -0.4575306, 0.32636842, -0.4087785...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,</td>\n",
       "      <td>[0.487278, -0.37566534, 0.41073442, -0.3688913...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>[0.64068377, -0.28513005, 0.12464522, -0.05887...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vocab                                                emb\n",
       "0  <unk>  [0.10041629, 0.21012346, 0.16489458, -0.108804...\n",
       "1  <pad>  [-0.020771498, 0.32556504, 0.059507508, -0.014...\n",
       "2    the  [0.5092548, -0.4575306, 0.32636842, -0.4087785...\n",
       "3      ,  [0.487278, -0.37566534, 0.41073442, -0.3688913...\n",
       "4     of  [0.64068377, -0.28513005, 0.12464522, -0.05887..."
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_df = pd.read_pickle(\"vocab_emb\")\n",
    "our_vectors = vocab_df['emb'].tolist()\n",
    "our_vectors = torch.Tensor(our_vectors)\n",
    "\n",
    "TEXT.vocab.vectors = our_vectors\n",
    "\n",
    "our_vectors.shape\n",
    "vocab_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYEPbRvuhbBX"
   },
   "source": [
    "We can check how many tokens and tags are in our vocabulary by getting their length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V2Xztw2dhbBX",
    "outputId": "e29c56da-799a-4355-89a6-e0db0fa23871"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 23221\n",
      "Unique tokens in PTB_TAGS vocabulary: 50\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in PTB_TAGS vocabulary: {len(PTB_TAGS.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJlPLaVnhbBX"
   },
   "source": [
    "Exploring the vocabulary, we can check the most common tokens within our texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pVlNKqT2hbBZ",
    "outputId": "04234103-0bd6-423c-8da9-aabe5d219144"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 65953), (',', 56119), ('of', 31192), ('to', 28283), ('and', 26983), ('a', 22699), ('in', 21868), ('that', 13682), ('is', 12048), (\"'s\", 11001), ('-', 10852), ('for', 9815), ('it', 8879), ('on', 7303), ('/.', 7165), ('with', 6603), ('as', 6069), ('this', 5879), ('was', 5859), ('are', 5784)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsvxsplchbBZ"
   },
   "source": [
    "We can see the vocabularies for both of our tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtRiHvtBhbBa",
    "outputId": "e771435c-9966-4a00-b62e-bf982e279950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', 'NN', 'IN', 'DT', 'NNP', 'JJ', 'NNS', ',', 'RB', 'PRP', 'VB', 'CC', 'VBD', 'VBZ', 'CD', 'VBN', 'VBP', 'VBG', 'TO', 'MD', 'PRP$', '.', 'HYPH', 'POS', \"''\", '``', 'WDT', 'UH', 'WP', ':', 'RP', 'WRB', 'NNPS', 'JJR', '$', 'EX', 'JJS', '-RRB-', '-LRB-', 'RBR', 'XX', 'PDT', 'RBS', 'FW', 'NFP', 'SYM', 'LS', 'WP$', 'ADD', 'AFX']\n"
     ]
    }
   ],
   "source": [
    "print(PTB_TAGS.vocab.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPPxrsL1hbBb"
   },
   "source": [
    "We can also see how many of each tag are in our vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2TIUrQMghbBb",
    "outputId": "749c4cad-1a32-42f9-f726-1543796a61ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NN', 166558), ('IN', 137756), ('DT', 110923), ('NNP', 103729), ('JJ', 76184), ('NNS', 67555), (',', 56740), ('RB', 50828), ('PRP', 39402), ('VB', 38789), ('CC', 35281), ('VBD', 32519), ('VBZ', 31577), ('CD', 26735), ('VBN', 26419), ('VBP', 23064), ('VBG', 22114), ('TO', 18006), ('MD', 13413), ('PRP$', 12240), ('.', 10836), ('HYPH', 10164), ('POS', 8493), (\"''\", 6438), ('``', 6405), ('WDT', 5842), ('UH', 5158), ('WP', 4848), (':', 4684), ('RP', 4573), ('WRB', 4285), ('NNPS', 3744), ('JJR', 3591), ('$', 2310), ('EX', 2174), ('JJS', 2071), ('-RRB-', 2025), ('-LRB-', 1999), ('RBR', 1804), ('XX', 1189), ('PDT', 859), ('RBS', 769), ('FW', 626), ('NFP', 437), ('SYM', 319), ('LS', 230), ('WP$', 188), ('ADD', 181), ('AFX', 11)]\n"
     ]
    }
   ],
   "source": [
    "print(PTB_TAGS.vocab.freqs.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAbDlX3ahbBb"
   },
   "source": [
    "We can also view how common each of the tags are within the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "XCg4h3RJhbBc"
   },
   "outputs": [],
   "source": [
    "def tag_percentage(tag_counts):\n",
    "    \n",
    "    total_count = sum([count for tag, count in tag_counts])\n",
    "    \n",
    "    tag_counts_percentages = [(tag, count, count/total_count) for tag, count in tag_counts]\n",
    "        \n",
    "    return tag_counts_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "io3wnhlwhbBc",
    "outputId": "24e4f868-bfb3-4f0a-cb57-2a9eb6e75777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag\t\tCount\t\tPercentage\n",
      "\n",
      "NN\t\t166558\t\t14.0%\n",
      "IN\t\t137756\t\t11.6%\n",
      "DT\t\t110923\t\t 9.4%\n",
      "NNP\t\t103729\t\t 8.7%\n",
      "JJ\t\t76184\t\t 6.4%\n",
      "NNS\t\t67555\t\t 5.7%\n",
      ",\t\t56740\t\t 4.8%\n",
      "RB\t\t50828\t\t 4.3%\n",
      "PRP\t\t39402\t\t 3.3%\n",
      "VB\t\t38789\t\t 3.3%\n",
      "CC\t\t35281\t\t 3.0%\n",
      "VBD\t\t32519\t\t 2.7%\n",
      "VBZ\t\t31577\t\t 2.7%\n",
      "CD\t\t26735\t\t 2.3%\n",
      "VBN\t\t26419\t\t 2.2%\n",
      "VBP\t\t23064\t\t 1.9%\n",
      "VBG\t\t22114\t\t 1.9%\n",
      "TO\t\t18006\t\t 1.5%\n",
      "MD\t\t13413\t\t 1.1%\n",
      "PRP$\t\t12240\t\t 1.0%\n",
      ".\t\t10836\t\t 0.9%\n",
      "HYPH\t\t10164\t\t 0.9%\n",
      "POS\t\t8493\t\t 0.7%\n",
      "''\t\t6438\t\t 0.5%\n",
      "``\t\t6405\t\t 0.5%\n",
      "WDT\t\t5842\t\t 0.5%\n",
      "UH\t\t5158\t\t 0.4%\n",
      "WP\t\t4848\t\t 0.4%\n",
      ":\t\t4684\t\t 0.4%\n",
      "RP\t\t4573\t\t 0.4%\n",
      "WRB\t\t4285\t\t 0.4%\n",
      "NNPS\t\t3744\t\t 0.3%\n",
      "JJR\t\t3591\t\t 0.3%\n",
      "$\t\t2310\t\t 0.2%\n",
      "EX\t\t2174\t\t 0.2%\n",
      "JJS\t\t2071\t\t 0.2%\n",
      "-RRB-\t\t2025\t\t 0.2%\n",
      "-LRB-\t\t1999\t\t 0.2%\n",
      "RBR\t\t1804\t\t 0.2%\n",
      "XX\t\t1189\t\t 0.1%\n",
      "PDT\t\t859\t\t 0.1%\n",
      "RBS\t\t769\t\t 0.1%\n",
      "FW\t\t626\t\t 0.1%\n",
      "NFP\t\t437\t\t 0.0%\n",
      "SYM\t\t319\t\t 0.0%\n",
      "LS\t\t230\t\t 0.0%\n",
      "WP$\t\t188\t\t 0.0%\n",
      "ADD\t\t181\t\t 0.0%\n",
      "AFX\t\t11\t\t 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Tag\\t\\tCount\\t\\tPercentage\\n\")\n",
    "\n",
    "for tag, count, percent in tag_percentage(PTB_TAGS.vocab.freqs.most_common()):\n",
    "    print(f\"{tag}\\t\\t{count}\\t\\t{percent*100:4.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pItqEpUDhbBe"
   },
   "source": [
    "The final part of data preparation is handling the iterator. \n",
    "\n",
    "This will be iterated over to return batches of data to process. Here, we set the batch size and the `device` - which is used to place the batches of tensors on our GPU, if we have one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uNteuVkshbBf",
    "outputId": "bae351b0-71e9-426d-a291-530b861115cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "UBGp8V1HhbBg"
   },
   "outputs": [],
   "source": [
    "class BiLSTMPOSTagger(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim, \n",
    "                 output_dim, \n",
    "                 n_layers, \n",
    "                 bidirectional, \n",
    "                 dropout, \n",
    "                 pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            num_layers = n_layers, \n",
    "                            bidirectional = bidirectional,\n",
    "                            dropout = dropout if n_layers > 1 else 0)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #pass text through embedding layer\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        \n",
    "        \n",
    "        #pass embeddings into LSTM\n",
    "        outputs, _ = self.lstm(embedded)\n",
    "        \n",
    "        #we use our outputs to make a prediction of what the tag should be\n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "        \n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "IFL4snSRhbBg"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 768\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = len(PTB_TAGS.vocab)\n",
    "N_LAYERS = 1\n",
    "BIDIRECTIONAL = False\n",
    "DROPOUT = 0\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = BiLSTMPOSTagger(INPUT_DIM, \n",
    "                        EMBEDDING_DIM, \n",
    "                        HIDDEN_DIM, \n",
    "                        OUTPUT_DIM, \n",
    "                        N_LAYERS, \n",
    "                        BIDIRECTIONAL, \n",
    "                        DROPOUT, \n",
    "                        PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IRdAMpGhbBh"
   },
   "source": [
    "We initialize the weights from a simple Normal distribution. Again, there may be a better initialization scheme for this model and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JvKArNrKhbBh",
    "outputId": "52912991-0a12-4eb3-8e70-963f7696ac7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMPOSTagger(\n",
       "  (embedding): Embedding(23221, 768, padding_idx=1)\n",
       "  (lstm): LSTM(768, 128)\n",
       "  (fc): Linear(in_features=128, out_features=50, bias=True)\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qf3R7kZhhbBj",
    "outputId": "1d854748-09c5-427f-b4c9-0f23f3994d17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23221, 768])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uq17LlCwhbBk",
    "outputId": "806ffeea-fa82-48fc-b9d6-f9c51a7a01c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1004,  0.2101,  0.1649,  ...,  0.3756, -0.3962,  0.6146],\n",
       "        [-0.0208,  0.3256,  0.0595,  ...,  0.0843, -0.2711,  0.7543],\n",
       "        [ 0.5093, -0.4575,  0.3264,  ..., -0.1868,  0.0561,  0.2649],\n",
       "        ...,\n",
       "        [ 0.1004, -0.1152, -0.2222,  ..., -0.2833,  0.4196,  1.0131],\n",
       "        [-0.1719, -0.6915,  0.8222,  ...,  0.0559,  0.4705,  0.4590],\n",
       "        [-0.1138, -0.4025,  0.2471,  ...,  0.1777,  0.1432,  0.5662]])"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hKD_AZBbhbBk",
    "outputId": "ebdc6273-210e-4e21-8938-8732b4f713bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1004,  0.2101,  0.1649,  ...,  0.3756, -0.3962,  0.6146],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.5093, -0.4575,  0.3264,  ..., -0.1868,  0.0561,  0.2649],\n",
      "        ...,\n",
      "        [ 0.1004, -0.1152, -0.2222,  ..., -0.2833,  0.4196,  1.0131],\n",
      "        [-0.1719, -0.6915,  0.8222,  ...,  0.0559,  0.4705,  0.4590],\n",
      "        [-0.1138, -0.4025,  0.2471,  ...,  0.1777,  0.1432,  0.5662]])\n"
     ]
    }
   ],
   "source": [
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sL41u5rghbBk"
   },
   "source": [
    "We then define our optimizer, used to update our parameters w.r.t. their gradients. We use Adam with the default learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "JvcFwwQDhbBk"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "s8c0Tv5ghbBl"
   },
   "outputs": [],
   "source": [
    "TAG_PAD_IDX = PTB_TAGS.vocab.stoi[PTB_TAGS.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "AC5GM5ynhbBl"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "ddRxB8FEhbBl"
   },
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y, tag_pad_idx):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
    "    return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "ZKK7d4LDhbBl"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        text = batch.text\n",
    "        tags = batch.ptbtags\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        predictions = model(text)\n",
    "        \n",
    "       \n",
    "        \n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "        \n",
    "        loss = criterion(predictions, tags)\n",
    "                \n",
    "        acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "nJyZ6jqzhbBl"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text = batch.text\n",
    "            tags = batch.ptbtags\n",
    "            \n",
    "            predictions = model(text)\n",
    "            \n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "            \n",
    "            loss = criterion(predictions, tags)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sv74NRO-hbBm"
   },
   "source": [
    "Next, we have a small function that tells us how long an epoch takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "JwHQcbM-hbBm"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEk7YlnRhbBm"
   },
   "source": [
    "Finally, we train our model!\n",
    "\n",
    "After each epoch we check if our model has achieved the best validation loss so far. If it has then we save the parameters of this model and we will use these \"best\" parameters to calculate performance over our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rVyxtJmhbBm",
    "outputId": "aff6c4b4-2561-44cb-e26c-f3a9bb9e64c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 26s\n",
      "\tTrain Loss: 0.303 | Train Acc: 90.98%\n",
      "\t Val. Loss: 0.229 |  Val. Acc: 92.31%\n",
      "Epoch: 02 | Epoch Time: 0m 25s\n",
      "\tTrain Loss: 0.162 | Train Acc: 94.44%\n",
      "\t Val. Loss: 0.222 |  Val. Acc: 92.62%\n",
      "Epoch: 03 | Epoch Time: 0m 25s\n",
      "\tTrain Loss: 0.139 | Train Acc: 95.20%\n",
      "\t Val. Loss: 0.218 |  Val. Acc: 92.94%\n",
      "Epoch: 04 | Epoch Time: 0m 25s\n",
      "\tTrain Loss: 0.122 | Train Acc: 95.76%\n",
      "\t Val. Loss: 0.224 |  Val. Acc: 92.82%\n",
      "Epoch: 05 | Epoch Time: 0m 25s\n",
      "\tTrain Loss: 0.107 | Train Acc: 96.28%\n",
      "\t Val. Loss: 0.236 |  Val. Acc: 92.78%\n",
      "Epoch: 06 | Epoch Time: 0m 25s\n",
      "\tTrain Loss: 0.095 | Train Acc: 96.70%\n",
      "\t Val. Loss: 0.242 |  Val. Acc: 92.64%\n",
      "Epoch: 07 | Epoch Time: 0m 25s\n",
      "\tTrain Loss: 0.085 | Train Acc: 97.07%\n",
      "\t Val. Loss: 0.253 |  Val. Acc: 92.73%\n",
      "Epoch: 08 | Epoch Time: 0m 25s\n",
      "\tTrain Loss: 0.077 | Train Acc: 97.36%\n",
      "\t Val. Loss: 0.265 |  Val. Acc: 92.63%\n",
      "Epoch: 09 | Epoch Time: 0m 25s\n",
      "\tTrain Loss: 0.069 | Train Acc: 97.64%\n",
      "\t Val. Loss: 0.273 |  Val. Acc: 92.68%\n",
      "Epoch: 10 | Epoch Time: 0m 25s\n",
      "\tTrain Loss: 0.063 | Train Acc: 97.86%\n",
      "\t Val. Loss: 0.288 |  Val. Acc: 92.53%\n",
      "\t Test Loss: 0.207 |  Test Acc: 93.12%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, TAG_PAD_IDX)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
    "print(f'\\t Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTUBZjkjhbBm"
   },
   "source": [
    "We then load our \"best\" parameters and evaluate \n",
    "performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dtUklU0hbBn",
    "outputId": "91790da0-dceb-48f9-e654-90b10fa05ccf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.207 |  Test Acc: 93.12%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "B6wGY28hhbBn"
   },
   "outputs": [],
   "source": [
    "def tag_sentence(model, device, sentence, text_field, tag_field):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('en')\n",
    "        tokens = [token.text for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token for token in sentence]\n",
    "\n",
    "    if text_field.lower:\n",
    "        tokens = [t.lower() for t in tokens]\n",
    "        \n",
    "    numericalized_tokens = [text_field.vocab.stoi[t] for t in tokens]\n",
    "\n",
    "    unk_idx = text_field.vocab.stoi[text_field.unk_token]\n",
    "    \n",
    "    unks = [t for t, n in zip(tokens, numericalized_tokens) if n == unk_idx]\n",
    "    \n",
    "    token_tensor = torch.LongTensor(numericalized_tokens)\n",
    "    \n",
    "    token_tensor = token_tensor.unsqueeze(-1).to(device)\n",
    "         \n",
    "    predictions = model(token_tensor)\n",
    "    \n",
    "    top_predictions = predictions.argmax(-1)\n",
    "    \n",
    "    predicted_tags = [tag_field.vocab.itos[t.item()] for t in top_predictions]\n",
    "    \n",
    "    return tokens, predicted_tags, unks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmNAcdavhbBn"
   },
   "source": [
    "We'll get an already tokenized example from the training set and test our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kt6WHpt6hbBn",
    "outputId": "82a69db9-b22c-4071-8b9e-c390cbda9667"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['had1999', 'in', 'a', 'unique', 'way', ',', 'a', 'young', 'saudi', 'woman', 'has', 'resorted', 'to', 'issuing', 'a', 'sound', 'tape', 'in', 'which', 'she', 'mourns', 'her', 'brother', 'murdered', 'in', 'hafr', 'al', 'batin', ',', 'in', 'the', 'hope', 'of', 'rekindling', 'interest', 'in', 'his', 'case', ',', 'in', 'which', '3', 'young', 'men', 'were', 'accused', 'of', 'killing', 'him', 'and', 'which', 'has', 'not', 'so', 'far', 'been', 'resolved']\n"
     ]
    }
   ],
   "source": [
    "example_index = 1\n",
    "\n",
    "sentence = vars(train_data.examples[example_index])['text']\n",
    "actual_tags = vars(train_data.examples[example_index])['ptbtags']\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EXs14A7vhbBn",
    "outputId": "0a4e892a-43d9-4197-fc5c-9fb7dde7c77a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['had1999', 'rekindling']\n"
     ]
    }
   ],
   "source": [
    "tokens, pred_tags, unks = tag_sentence(model, \n",
    "                                       device, \n",
    "                                       sentence, \n",
    "                                       TEXT, \n",
    "                                       PTB_TAGS)\n",
    "\n",
    "print(unks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53lYks7khbBo"
   },
   "source": [
    "We can then check how well it did. Surprisingly, it got every token correct, including the two that were unknown tokens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KgcZnJYUhbBo",
    "outputId": "9913248f-2c1e-47c6-cc69-cfd54f144fe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
      "\n",
      "NNP\t\tNNP\t\t✔\t\thad1999\n",
      "IN\t\tIN\t\t✔\t\tin\n",
      "DT\t\tDT\t\t✔\t\ta\n",
      "JJ\t\tJJ\t\t✔\t\tunique\n",
      "NN\t\tNN\t\t✔\t\tway\n",
      ",\t\t,\t\t✔\t\t,\n",
      "DT\t\tDT\t\t✔\t\ta\n",
      "JJ\t\tJJ\t\t✔\t\tyoung\n",
      "JJ\t\tJJ\t\t✔\t\tsaudi\n",
      "NN\t\tNN\t\t✔\t\twoman\n",
      "VBZ\t\tVBZ\t\t✔\t\thas\n",
      "VBN\t\tVBN\t\t✔\t\tresorted\n",
      "IN\t\tIN\t\t✔\t\tto\n",
      "VBG\t\tVBG\t\t✔\t\tissuing\n",
      "DT\t\tDT\t\t✔\t\ta\n",
      "NN\t\tNN\t\t✔\t\tsound\n",
      "NN\t\tNN\t\t✔\t\ttape\n",
      "IN\t\tIN\t\t✔\t\tin\n",
      "WDT\t\tWDT\t\t✔\t\twhich\n",
      "PRP\t\tPRP\t\t✔\t\tshe\n",
      "VBZ\t\tVBZ\t\t✔\t\tmourns\n",
      "PRP$\t\tPRP$\t\t✔\t\ther\n",
      "NN\t\tNN\t\t✔\t\tbrother\n",
      "VBN\t\tVBN\t\t✔\t\tmurdered\n",
      "IN\t\tIN\t\t✔\t\tin\n",
      "NNP\t\tNNP\t\t✔\t\thafr\n",
      "NNP\t\tNNP\t\t✔\t\tal\n",
      "NNP\t\tNNP\t\t✔\t\tbatin\n",
      ",\t\t,\t\t✔\t\t,\n",
      "IN\t\tIN\t\t✔\t\tin\n",
      "DT\t\tDT\t\t✔\t\tthe\n",
      "NN\t\tNN\t\t✔\t\thope\n",
      "IN\t\tIN\t\t✔\t\tof\n",
      "VBG\t\tVBG\t\t✔\t\trekindling\n",
      "NN\t\tNN\t\t✔\t\tinterest\n",
      "IN\t\tIN\t\t✔\t\tin\n",
      "PRP$\t\tPRP$\t\t✔\t\this\n",
      "NN\t\tNN\t\t✔\t\tcase\n",
      ",\t\t,\t\t✔\t\t,\n",
      "IN\t\tIN\t\t✔\t\tin\n",
      "WDT\t\tWDT\t\t✔\t\twhich\n",
      "CD\t\tCD\t\t✔\t\t3\n",
      "JJ\t\tJJ\t\t✔\t\tyoung\n",
      "NNS\t\tNNS\t\t✔\t\tmen\n",
      "VBD\t\tVBD\t\t✔\t\twere\n",
      "VBN\t\tVBN\t\t✔\t\taccused\n",
      "IN\t\tIN\t\t✔\t\tof\n",
      "VBG\t\tVBG\t\t✔\t\tkilling\n",
      "PRP\t\tPRP\t\t✔\t\thim\n",
      "CC\t\tCC\t\t✔\t\tand\n",
      "WDT\t\tWDT\t\t✔\t\twhich\n",
      "VBZ\t\tVBZ\t\t✔\t\thas\n",
      "RB\t\tRB\t\t✔\t\tnot\n",
      "RB\t\tRB\t\t✔\t\tso\n",
      "RB\t\tRB\t\t✔\t\tfar\n",
      "VBN\t\tVBN\t\t✔\t\tbeen\n",
      "VBN\t\tVBN\t\t✔\t\tresolved\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
    "\n",
    "for token, pred_tag, actual_tag in zip(tokens, pred_tags, actual_tags):\n",
    "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
    "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ms3x8lWohbBo"
   },
   "source": [
    "Let's now make up our own sentence and see how well the model does.\n",
    "\n",
    "Our example sentence below has every token within the model's vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1rMCT59hbBo",
    "outputId": "1a95959c-6700-44dd-ae5c-97a6c0cceb24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neural', 'netwoks', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Last semester I participated in \"Neural Netwoks implementation and application\" course, it was very interesting.'\n",
    "\n",
    "tokens, tags, unks = tag_sentence(model, \n",
    "                                  device, \n",
    "                                  sentence, \n",
    "                                  TEXT, \n",
    "                                 PTB_TAGS)\n",
    "\n",
    "print(unks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsPZ5HrxhbBo"
   },
   "source": [
    "Looking at the sentence it seems like it gave sensible tags to every token!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MPw5MPVohbBo",
    "outputId": "d3eb894d-963d-4b60-de5b-25ea7b6eda4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. Tag\tToken\n",
      "\n",
      "JJ\t\tlast\n",
      "NN\t\tsemester\n",
      "PRP\t\ti\n",
      "VBD\t\tparticipated\n",
      "IN\t\tin\n",
      "``\t\t\"\n",
      "NNP\t\tneural\n",
      "NNP\t\tnetwoks\n",
      "NN\t\timplementation\n",
      "CC\t\tand\n",
      "NN\t\tapplication\n",
      "``\t\t\"\n",
      "NN\t\tcourse\n",
      ",\t\t,\n",
      "PRP\t\tit\n",
      "VBD\t\twas\n",
      "RB\t\tvery\n",
      "JJ\t\tinteresting\n",
      "NN\t\t.\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred. Tag\\tToken\\n\")\n",
    "\n",
    "for token, tag in zip(tokens, tags):\n",
    "    print(f\"{tag}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yaBGTCREWhAW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BiLSTM_for_PoS_Tagging.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
